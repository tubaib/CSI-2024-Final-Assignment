pip install gensim nltk
import gensim
import gensim.corpora as corpora
from gensim.models import LdaModel
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string


nltk.download('punkt')
nltk.download('stopwords')


documents = [
    "I love machine learning. Its applications are vast and amazing.",
    "Natural language processing is a fascinating field.",
    "Deep learning is a branch of machine learning.",
    "There are many machine learning algorithms such as regression, classification, and clustering."
]


stop_words = set(stopwords.words('english'))
punctuation = set(string.punctuation)

def preprocess(doc):
    tokens = word_tokenize(doc.lower())
    tokens = [word for word in tokens if word.isalpha() and word not in stop_words and word not in punctuation]
    return tokens

processed_docs = [preprocess(doc) for doc in documents]


id2word = corpora.Dictionary(processed_docs)
corpus = [id2word.doc2bow(text) for text in processed_docs]


lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=2, random_state=42, passes=10)


for idx, topic in lda_model.print_topics(-1):
    print(f"Topic: {idx}\nWords: {topic}\n")
